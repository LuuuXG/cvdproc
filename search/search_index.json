{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CVDProc: CerebroVascular Disease imaging Processing","text":"<p>Warning</p> <p>This package is intended for research purposes only, to facilitate reproducibility of neuroimaging analyses in our center. The authors do NOT guarantee the correctness or clinical validity of all processing workflows.</p> <p>This repository currently serves as a public display for MRI image preprocessing and analysis, aimed at enhancing the transparency and reproducibility of research conducted at our center.</p>"},{"location":"containers/","title":"Containers used in cvdproc","text":"<p>The containers used in cvdproc are listed below:</p>"},{"location":"containers/#docker-images","title":"Docker Images:","text":"<ul> <li>kilianhett/chp_seg:1.0.1</li> <li>leonyichencai/synb0-disco:v3.1</li> <li>nipreps/fmriprep:v25.1.4</li> <li>pennlinc/aslprep:v25.0.0</li> <li>pennlinc/qsiprep:v1.0.1</li> <li>pennlinc/qsirecon:v1.0.0</li> <li>pennlinc/xcp_d:v0.11.0</li> <li>segcsvd_rc03:latest</li> <li>ytzero/synbold-disco:v1.4</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#download","title":"Download","text":"<p>You can download the source code by cloning the GitHub repository: <pre><code>git clone https://github.com/LuuuXG/cvdproc.git\n</code></pre> Or download it manually from the GitHub homepage.</p>"},{"location":"installation/#installation_1","title":"Installation","text":"<p>Please create a new conda environment, which is more suitable for this package.</p> <pre><code># Please replace &lt;env_name&gt; with the name you want for the environment\nconda create -n &lt;env_name&gt; python=3.7 openssl=1.1.1\nconda activate &lt;env_name&gt;\n</code></pre> <p>Python Version</p> <p>Due to the features of the early version of  SHIVA model, python 3.7 is used for tensorflow compatibility. We are working on updating the code to support higher versions of Python by using SHiVAi. For example, LST-AI for WMH segmentation needs python 3.8 or higher. Currently, the solution is to use a different environment for different pipelines if necessary.</p> <p>Then, navigate to the directory where you downloaded the code (the folder containing <code>setup.py</code>), and run the following command:</p> <pre><code># Use -e to allow modification of the code without needing to reinstall.\n# Here &lt;/path/to/cvdproc&gt; is the folder containing `setup.py`\npip install -e /path/to/cvdproc\n\n# If it is necessary to use mirror\npip install -e /path/to/cvdproc -i https://pypi.tuna.tsinghua.edu.cn/simple\n</code></pre> <p>tensorflow and torch</p> <p>Because these two packages are large in size, we do not specify them in <code>setup.py</code>. However, they will be used in the subsequent code. Please install them as needed.</p>"},{"location":"usage/","title":"Usage","text":"<p>Please refer to the different pages for specific functions:</p> <p>If you need to create a BIDS dataset from DICOM files, please refer to:</p> <ul> <li>dcm2bids: Create BIDS dataset from DICOM files.</li> </ul> <p>Or if you already have a dataset in BIDS format, you can use the following functions:</p> <ul> <li>Pipelines: Different pipelines for MRI preprocessing and analysis.</li> </ul>"},{"location":"dcm2bids/dcm2bids/","title":"dcm2bids","text":"<p>We are using the dcm2bids to convert DICOM files to BIDS format. Before running the code, please make sure you have installed the <code>dcm2bids</code> (it should have been installed when you installed the cvdproc) and <code>dcm2niix</code> (you can install it via <code>apt install dcm2niix</code>)</p>"},{"location":"dcm2bids/dcm2bids/#create-a-new-bids-dataset","title":"Create a new BIDS dataset","text":"<p>If you want to create a new BIDS dataset, you can use the following command:</p> <pre><code>cvdproc --run_initialization &lt;path/to/the/folder/you/want/to/create&gt;\n</code></pre> <p>You don't need to create the folder manually, the code will create it for you.</p>"},{"location":"dcm2bids/dcm2bids/#convert-dicom-to-bids","title":"Convert DICOM to BIDS","text":"<p>If you already have a BIDS root folder or just created one with the command above, you can follow the steps below to convert DICOM files to BIDS format.</p>"},{"location":"dcm2bids/dcm2bids/#create-a-dcm2bids-configuration-file","title":"Create a dcm2bids configuration file","text":"<p>Please refer to the official dcm2bids documentation How to create a configuration file for the most detailed guidance.</p> <p>Here we take the example of converting a 3D T1w image to BIDS format.</p> <p>Create a file named <code>dcm2bids_config.json</code> in the <code>code</code> folder of your BIDS root directory (the file name and location can be changed, but we name it this way for convenience). The content of the file is as follows:</p> <pre><code>{\n  \"descriptions\": [\n    {\n      \"datatype\": \"anat\",\n      \"suffix\": \"T1w\",\n      \"criteria\": {\n        \"SeriesDescription\": \"*mprage*\",\n      }\n    }\n  ]\n}\n</code></pre> <p>The most important part of the configuration file is the <code>criteria</code> field, which specifies how to match the DICOM files. In this case, we are matching the <code>SeriesDescription</code> field with a regular expression <code>*mprage*</code>. If your DICOM files do not have this field or have a different value, you can try to use the <code>dcm2bids_helper</code> command to get the information, or you can use <code>dcm2niix</code> (which can also be found in MRIcroGL) to get the information in the JSON file. You can also skip this step (just copy the content above) and wait for the next step to see how we solve it.</p>"},{"location":"dcm2bids/dcm2bids/#create-a-cvdproc-configuration-file","title":"Create a cvdproc configuration file","text":"<p>cvdproc config file</p> <p>This step is very important because it is the core of the <code>cvdproc</code> command to specify parameters.</p> <p>Create a <code>config.yml</code> file in the <code>code</code> folder (note that we use the yaml format), and the content is as follows:</p> <pre><code># You need to specify the BIDS root folder here\nbids_dir: /mnt/f/BIDS/demo_wmh\n## You need to specify the dcm2bids configuration file here\ndcm2bids: \n  config_file: /mnt/f/BIDS/demo_wmh/code/dcm2bids_config.json\n</code></pre> <p>Remember to change the <code>bids_dir</code> and <code>config_file</code> paths to your own paths. The <code>bids_dir</code> is the root folder of your BIDS dataset, and the <code>config_file</code> is the path to the dcm2bids configuration file you just created. And then you need to move or copy the folder containing the DICOM files for a single subject into the <code>sourcedata</code> folder of the BIDS root directory. For example, if you have a folder named <code>DICOM_01</code> containing the DICOM files for a single subject's baseline acquisition, you need to move or copy it to <code>/mnt/f/BIDS/demo_wmh/sourcedata/DICOM_01</code>. The final folder structure should look like this:</p> <pre><code>/mnt/f/BIDS/demo_wmh\n\u251c\u2500\u2500 code\n\u2502   \u251c\u2500\u2500 config.yml\n\u2502   \u2514\u2500\u2500 dcm2bids_config.json\n\u251c\u2500\u2500 sourcedata\n\u2502   \u2514\u2500\u2500 DICOM_01\n\u2514\u2500\u2500 .bidsignore\n</code></pre> <p>Info</p> <p>Because the original DICOM images obtained in actual research may have different structures, the file structure under the subject's DICOM folder may vary. However, it should be noted that there is no need to preprocess the subfolders under the DICOM folder in advance (for example, a common practice is to make one subfolder correspond to one scanning sequence). This is because <code>dcm2bids</code> will convert all DICOM files found under the folder, even if only a few sequences are specified in the json file (so, for example, when EPI sequences with DWI or multi-echo GRE sequences are included, the conversion time may take several minutes, but fortunately, theoretically, such conversion only needs to be done once).</p> <p>After the above preparation, you need to specify the subject ID and session ID for the converted subject. For example, if the DICOM files are stored in <code>DICOM_01</code>, you need to set the subject ID to <code>SUB0001</code> and the session ID to <code>01</code> to indicate baseline data. Run:</p> <pre><code>cvdproc --config_file /mnt/f/BIDS/demo_wmh/code/config.yml \\\n  --run_dcm2bids \\\n  --subject_id SUB0001 --session_id 01 \\\n  --dicom_subdir DICOM_01\n</code></pre> <p>Theoretically, the folder <code>/mnt/f/BIDS/demo_wmh/sub-SUB0001</code> should be created to store the subject's data. However, since we did not check the <code>SeriesDescription</code> field of the DICOM files in advance, it should prompt that no matching files were found, and the subject folder was not created. Next, we can open the <code>tmp_dcm2bids</code> folder to check the output of <code>dcm2bids</code>, find the json file of the image of interest, and then find the <code>SeriesDescription</code> field (or other fields you want to match) to modify the corresponding content in <code>dcm2bids_config.json</code>, and run the above command again.</p> <p>At this time, it should be able to successfully obtain the <code>sub-SUB0001</code> folder, which contains the <code>ses-01</code> subfolder. Because <code>dcm2bids</code> will automatically look for images that meet the criteria under <code>tmp_dcm2bids</code>, instead of converting all images again.</p>"},{"location":"dcm2bids/dcm2bids/#bidsignore","title":".bidsignore","text":"<p>We can notice that there is a <code>.bidsignore</code> file in the bids root directory, which is used to ignore files that do not belong to the BIDS format. If we open it, we will find that it contains the <code>tmp_dcm2bids</code> folder, which is the temporary folder generated when we run the dcm2bids command. The <code>dcm2bids</code> will automatically add it to the <code>.bidsignore</code>.</p> <p>It is worth noting that <code>dcm2bids</code> itself is very flexible and allows the generation of folders that do not meet the BIDS requirements (for example, I want to change the datatype and suffix in the json file to qsm and GRE respectively, which I believe is not currently specified in the BIDS specification, but this is more convenient for organizing data). In this case, we need to manually add these folders to the <code>.bidsignore</code> (for example: sub-*/ses-*/qsm/ to ignore each qsm folder). This is very necessary because various nipreps (such as fmriprep, qsiprep) include a check bids validation step (although it can be skipped, it is not recommended to do so, otherwise it is easy to have no error but the running process has problems), and these folders that do not meet the standard definition will cause errors.</p> <p>In addition, the BIDSLayout function of nipype seems to automatically exclude folders that do not meet the BIDS definition, regardless of whether they are added to the <code>.bidsignore</code>, which is also why we did not use it.</p>"},{"location":"pipelines/","title":"Pipelines Overview","text":""},{"location":"pipelines/#command-to-run-a-pipeline","title":"Command to Run a Pipeline","text":"<pre><code>cvdproc --config_file &lt;path/to/your/config/file&gt; --run_pipeline --pipeline &lt;pipeline name&gt; --subject_id &lt;subject id (with out -sub prefix)&gt; --session_id &lt;session id (with out -ses prefix)&gt;\n</code></pre> <p>Generally, parameters concerning the pipeline should be set in the configuration file (this configuration file has been mentioned in the dcm2bids section). As we already set the <code>bids_dir</code> parameter in the configuration file, we will need to add some new parameters: <pre><code># For example\nbids_dir: /mnt/f/BIDS/demo_wmh # we have done it in the dcm2bids section\ndcm2bids: \n  config_file: /mnt/f/BIDS/demo_wmh/code/dcm2bids_config.json\n# New things\noutput_dir: /mnt/f/BIDS/demo_wmh/derivatives # output directory, please use bids::/derivatives\npipelines:\n    wmh_quantification: # the pipeline name, can be changed to any available pipeline (see below)\n        # Then the pipeline-specific parameters go here\n        use_which_flair: \"acq-tra\"\n        use_which_t1w: 'acq-highres'\n        seg_threshold: 0.5\n        seg_method: \"LST\"\n        location_method: [\"Fazekas\", \"shiva\", \"McDonald\"]\n        ventmask_method: 'SynthSeg'\n        use_bianca_mask: false\n        normalize_to_mni: true\n</code></pre> The <code>--pipeline</code> parameter is used to specify which pipeline to run. The <code>--subject_id</code> and <code>--session_id</code> parameters are used to specify the subject and session to be processed. You can run multiple subjects and sessions serially by specifying multiple <code>--subject_id</code> and <code>--session_id</code> parameters. For example, if you want to run the <code>wmh_quantification</code> pipeline for subjects <code>SUB0001</code> and <code>SUB0002</code>, both at session <code>01</code>, you can run: <code>cvdproc --config_file /mnt/f/BIDS/demo_wmh/code/config.yml --run_pipeline --pipeline wmh_quantification --subject_id 0001 0002 --session_id 01 01</code>.</p> <p>The detailed parameters for each pipeline can be found in the respective documentation pages (see below). Parameters except for <code>subject</code>, <code>session</code>, and <code>output_path</code> should be set in the configuration file.</p>"},{"location":"pipelines/#currently-available-pipelines","title":"Currently Available Pipelines","text":""},{"location":"pipelines/#structural-mri-smri-pipelines","title":"Structural MRI (sMRI) Pipelines","text":"<ul> <li> Freesurfer recon-all (freesurfer)</li> <li> FSL anat (fsl_anat)</li> <li> T1w Registration to MNI space (t1_register)</li> <li> Anatomical Segmentation (anat_seg)</li> <li> WMH Quantification (wmh_quantification)</li> <li> PVS Quantification (pvs_quantification)</li> <li> CMB Quantification (cmb_quantification)</li> </ul>"},{"location":"pipelines/#diffusion-mri-dmri-pipelines","title":"Diffusion MRI (dMRI) Pipelines","text":"<ul> <li> General DWI Processing (dwi_pipeline)</li> <li> Lesion Quantification Toolkit (LQT) Pipeline (lqt_pipeline)</li> </ul>"},{"location":"pipelines/#functional-mri-fmri-pipelines","title":"Functional MRI (fMRI) Pipelines","text":"<ul> <li> fMRI Pipeline (fmri_pipeline)</li> </ul>"},{"location":"pipelines/#arterial-spin-labeling-asl-pipelines","title":"Arterial Spin Labeling (ASL) Pipelines","text":"<ul> <li> ASL Pipeline (asl_pipeline)</li> </ul>"},{"location":"pipelines/#quantitative-mri-qmri-pipelines","title":"Quantitative MRI (qMRI) Pipelines","text":"<ul> <li> QSM Pipeline (qsm_pipeline)</li> <li> SEPIA QSM (deprecated, archived as a record of the processing used in our paper) (sepia_qsm)</li> </ul>"},{"location":"pipelines/#dsc-mri-pwi-pipelines","title":"DSC-MRI (PWI) Pipelines","text":"<ul> <li> PWI Pipeline (pwi_pipeline)</li> </ul>"},{"location":"pipelines/dMRI/lqt_pipeline/","title":"LQT Pipeline","text":"<p>Using the Lesion Quantification Toolkit (LQT) to quantify lesion disconnection.</p> <p>Last updated: 2025-08-02, WYJ</p>"},{"location":"pipelines/dMRI/lqt_pipeline/#cvdproc.pipelines.dmri.lqt_pipeline.LQTPipeline.__init__","title":"<code>__init__</code>","text":"<p>LQT Pipeline for lesion disconnection analysis.</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>BIDSSubject</code> <p>A BIDS subject object.</p> required <code>session</code> <code>BIDSSession</code> <p>A BIDS session object.</p> required <code>output_path</code> <code>str</code> <p>Directory to save outputs.</p> required <code>seed_mask</code> <code>str</code> <p>Name of the seed mask folder in 'derivatives'. For example, if the ROI mask path is 'derivatives/lesion_mask/sub-XXX/ses-XXX/*infarction.nii.gz', then seed_mask='lesion_mask'.</p> <code>'lesion_mask'</code> <code>use_which_mask</code> <code>str</code> <p>Keyword to select the desired lesion mask. Default is 'infarction'. For example, if the lesion mask is 'derivatives/lesion_mask/sub-XXX/ses-XXX/*infarction.nii.gz', then use_which_mask='infarction'.</p> <code>'infarction'</code> <code>extract_from</code> <code>str</code> <p>If extracting results, please provide it.</p> <code>None</code>"},{"location":"pipelines/dMRI/lqt_pipeline/#cvdproc.pipelines.dmri.lqt_pipeline.LQTPipeline.check_data_requirements","title":"<code>check_data_requirements</code>","text":"<p>Will always return True, as the LQT pipeline will check the seed mask in MNI space during creation of the workflow.</p>"},{"location":"pipelines/dMRI/lqt_pipeline/#a-more-detailed-description","title":"A more detailed description:","text":"<p>Source: LQT</p> <p>Note</p> <p>LQT is implemented in R, so you need to have R installed on your system. Using R in WSL seems to have some instability, try changing the cores=4 parameter in 'cvdproc/pipelines/r/lqt_single_subject.R'.</p> <p>I recommend using the RStudio IDE (because we use rstudioapi in the script) and open 'cvdproc/pipelines/r/lqt_initialize.r' to initialize the LQT package: As the package is no longer being actively maintained, we included the package in 'cvdproc/pipelines/external/LQT' and we can install it from there. Then we need to copy some extension data to the package directory (data is in 'cvdproc/data/lqt/extdata'), which is done in the script. Doing this by following instructions in the LQT README seems incorrect as it will download a MacOS version of DSI Studio, which is not compatible with WSL Linux.</p>"},{"location":"pipelines/pwi/pwi_pipeline/","title":"PWI Pipeline","text":"<p>Postprocessing pipeline for Dynamic Susceptibility Contrast MRI (DSC-MRI) perfusion data (PWI).</p> <p>This pipeline is to: Calculate PWI maps from DSC-MRI data (rCBF, rCBV, MTT, TTP, K2)</p> <p>Last updated: 2025-07-27, WYJ</p>"},{"location":"pipelines/pwi/pwi_pipeline/#cvdproc.pipelines.pwi.pwi_pipeline.PWIPipeline.__init__","title":"<code>__init__</code>","text":"<p>Postprocessing pipeline for DSC-MRI perfusion data (PWI).</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>BIDSSubject</code> <p>A BIDS subject object.</p> required <code>session</code> <code>BIDSSession</code> <p>A BIDS session object.</p> required <code>output_path</code> <code>str</code> <p>Directory to save outputs.</p> required <code>use_which_pwi</code> <code>str</code> <p>Keyword to select the desired PWI file.</p> <code>'pwi'</code> <code>dsc_mri_toolbox_path</code> <code>str</code> <p>Path to the MATLAB dsc-mri-toolbox.</p> <code>None</code> <code>extract_from</code> <code>str</code> <p>If extracting results, please provide it.</p> <code>None</code>"},{"location":"pipelines/pwi/pwi_pipeline/#a-more-detailed-description","title":"A more detailed description:","text":"<ol> <li> <p>Strip the PWI data using SynthStrip to create a brain mask.</p> </li> <li> <p>Calculate the PWI concentration map (a 4D image).</p> </li> <li> <p>Auto select the AIF (arterial input function) from the concentration data. (Please refer to Auto AIF Selection)</p> </li> <li> <p>Generate the perfusion maps (rCBF, rCBV, MTT, TTP, K2) using the MATLAB-based dsc-mri-toolbox.</p> </li> </ol>"},{"location":"pipelines/qMRI/qsm_pipeline/","title":"QSM Pipeline","text":"<p>QSM Processing Pipeline using Sepia and QQNet.</p>"},{"location":"pipelines/qMRI/qsm_pipeline/#cvdproc.pipelines.qmri.qsm_pipeline.QSMPipeline.__init__","title":"<code>__init__</code>","text":"<p>QSM processing pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>BIDSSubject</code> <p>A BIDS subject object.</p> required <code>session</code> <code>BIDSSession</code> <p>A BIDS session object.</p> required <code>output_path</code> <code>str</code> <p>Output directory to save results.</p> required <code>use_which_t1w</code> <code>str</code> <p>Keyword to select the desired T1w image.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize QSM (and other scalar maps) to MNI space via T1w.</p> <code>False</code> <code>phase_image_correction</code> <code>bool</code> <p>If True, apply phase image correction for inter-slice phase polarity differences in the GE data. (https://github.com/kschan0214/sepia/discussions/93)</p> <code>False</code> <code>reverse_phase</code> <code>int</code> <p>Set to 1 to inverse phase polarity (for GE scanners).</p> <code>0</code>"},{"location":"pipelines/qMRI/qsm_pipeline/#a-more-detailed-description","title":"A more detailed description:","text":"<p>This pipeline contains the processing steps to compute Quantitative Susceptibility Mapping (QSM) and other scalar maps from multi-echo gradient echo (GRE) data by the following steps:</p> <ol> <li>QSM reconstruction using a combined approach from the SEPIA toolbox and Chisep toolbox, including:<ul> <li>Phase unwrapping (SEPIA: ROMEO total field calculation)</li> <li>Background field removal using V-SHARP (SEPIA)</li> <li>Dipole inversion using iLSQR (Chisep)</li> </ul> </li> </ol>"},{"location":"pipelines/qMRI/sepia_qsm/","title":"Sepia QSM","text":"<p>Pipeline for processing Quantitative Susceptibility Mapping (QSM) data using the SEPIA toolbox.</p>"},{"location":"pipelines/qMRI/sepia_qsm/#cvdproc.pipelines.qmri.sepia_qsm_pipeline.SepiaQSMPipeline.__init__","title":"<code>__init__</code>","text":"<p>Sepia QSM processing pipeline</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>BIDSSubject</code> <p>A BIDS subject object.</p> required <code>session</code> <code>BIDSSession</code> <p>A BIDS session object.</p> required <code>output_path</code> <code>str</code> <p>Output directory to save results.</p> required <code>use_which_t1w</code> <code>str</code> <p>Keyword to select the desired T1w image.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize QSM (and other scalar maps) to MNI space via T1w.</p> <code>False</code> <code>sepia_toolbox_path</code> <code>str</code> <p>Path to the SEPIA toolbox. If None, assumes SEPIA is in MATLAB path.</p> <code>None</code> <code>reverse_phase</code> <code>int</code> <p>Set to 1 to reverse phase polarity (for GE scanners).</p> <code>0</code>"},{"location":"pipelines/qMRI/sepia_qsm/#a-more-detailed-description","title":"A more detailed description:","text":"<p>This pipeline is deprecated. Please use the new QSM pipeline instead.</p> <p>This pipeline contains the processing steps to compute Quantitative Susceptibility Mapping (QSM) from multi-echo gradient echo (GRE) data using the SEPIA toolbox. It is used in our paper: </p> <p>[1] Wang Y, Ye C, Pan R, Tang B, Li C, Liu J, Tao W, Zhang X, Yang T, Yan Y, Jiang S, Lui S, Wu B. Cognitive implications and associated transcriptomic signatures of distinct regional iron depositions in cerebral small vessel disease. Alzheimers Dement. 2025 Apr;21(4):e70196. doi: 10.1002/alz.70196. PMID: 40257048; PMCID: PMC12010275.</p>"},{"location":"pipelines/sMRI/anat_seg/","title":"Anatomical Segmentation","text":""},{"location":"pipelines/sMRI/anat_seg/#cvdproc.pipelines.smri.anat_seg_pipeline.AnatSegPipeline","title":"<code>AnatSegPipeline</code>","text":"<p>Generating anatomical segmentation atlas from sMRI</p>"},{"location":"pipelines/sMRI/anat_seg/#cvdproc.pipelines.smri.anat_seg_pipeline.AnatSegPipeline.__init__","title":"<code>__init__</code>","text":"<p>Generating anatomical segmentation atlas from sMRI</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>object</code> <p>Subject object</p> required <code>session</code> <code>object</code> <p>Session object</p> required <code>output_path</code> <code>str</code> <p>Output directory</p> required <code>use_which_t1w</code> <code>str</code> <p>specific string to select T1w image, e.g. 'acq-highres'. If None, T1w image is not used</p> <code>'T1w'</code> <code>methods</code> <code>list</code> <p>List of methods to use. Options include 'synthseg' and 'chpseg'.</p> <code>['synthseg', 'chpseg']</code> <code>cpu_first</code> <code>bool</code> <p>Whether to use CPU first for SynthSeg (if available)</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments</p> <code>{}</code>"},{"location":"pipelines/sMRI/anat_seg/#a-more-detailed-description","title":"A more detailed description:","text":"<p>In this pipeline, we collect several anatomical segmentation methods for structural MRI (sMRI).</p> <ul> <li>SynthSeg</li> <li>chpseg: Using T1w image to segment the choroid plexus (CP) in lateral ventricles.</li> </ul>"},{"location":"pipelines/sMRI/pvs_quantification/","title":"pvs_quantification","text":"<p>Current SHiVAi pipeline (2025-06) seems to have problem handling html/pdf reports (for example, when facing NaN value). A workaround is to modify the code in <code>post.py</code> to simply skip the report generation step, which is not critical for the pipeline to run.</p> <pre><code>class SummaryReport(BaseInterface):\n    \"\"\"Make a summary report of preprocessing and prediction\"\"\"\n    input_spec = SummaryReportInputSpec\n    output_spec = SummaryReportOutputSpec\n\n    # def _run_interface(self, runtime):\n    #     \"\"\"\n    #     Build the report for the whole workflow. It contains segmentation statistics and\n    #     quality control figures.\n\n    #     \"\"\"\n    #     if self.inputs.anonymized:\n    #         subject_id = ''\n    #     else:\n    #         subject_id = self.inputs.subject_id\n\n    #     brain_vol_vox = nib.load(self.inputs.brainmask).get_fdata().astype(bool).sum()  # in voxels\n    #     pred_metrics_dict = {}  # Will contain the stats dataframe for each biomarker\n    #     pred_census_im_dict = {}  # Will contain the path to the swarm plot for each biomarker\n    #     pred_overlay_im_dict = {}  # Will contain the path to the figure with biomarkers overlaid on the brain\n    #     models_uid = {}  # Will contain the md5 hash for each file of each predictive model\n    #     pred_and_acq = self.inputs.pred_and_acq\n\n    #     # Generate the distribution figures for each prediction and fill models_uid\n    #     for pred in pred_and_acq:\n    #         lpred = pred.lower()  # \"pred\" is uppercase, so we also need a lowercase version\n    #         if pred == 'LAC':\n    #             name_in_plot = 'Lacuna'\n    #         else:\n    #             name_in_plot = pred\n    #         models_uid[pred] = {}\n    #         pred_metrics_dict[pred] = pd.read_csv(getattr(self.inputs, f'{lpred}_metrics_csv'))\n    #         if pred_metrics_dict[pred]['Number of clusters'].sum() == 0:  # No biomarker detected\n    #             pred_census_im_dict[pred] = None\n    #         else:\n    #             pred_census_im_dict[pred] = violinplot_from_census(getattr(self.inputs, f'{lpred}_census_csv'),\n    #                                                                self.inputs.resolution,\n    #                                                                name_in_plot)\n    #         pred_overlay_im_dict[pred] = getattr(self.inputs, f'{lpred}_overlay')\n    #         ids, url = get_md5_from_json(getattr(self.inputs, f'{lpred}_model_descriptor'), get_url=True)\n    #         models_uid[pred]['id'] = ids\n    #         if url:\n    #             models_uid[pred]['url'] = url\n\n    #     # set optional inputs to None if undefined\n    #     if isdefined(self.inputs.overlayed_brainmask_1):\n    #         overlayed_brainmask_1 = self.inputs.overlayed_brainmask_1\n    #     else:\n    #         overlayed_brainmask_1 = None\n    #     if isdefined(self.inputs.crop_brain_img):\n    #         crop_brain_img = self.inputs.crop_brain_img\n    #     else:\n    #         crop_brain_img = None\n    #     if isdefined(self.inputs.isocontour_slides_FLAIR_T1):\n    #         isocontour_slides_FLAIR_T1 = self.inputs.isocontour_slides_FLAIR_T1\n    #     else:\n    #         isocontour_slides_FLAIR_T1 = None\n    #     if isdefined(self.inputs.overlayed_brainmask_2):\n    #         overlayed_brainmask_2 = self.inputs.overlayed_brainmask_2\n    #     else:\n    #         overlayed_brainmask_2 = None\n    #     if isdefined(self.inputs.wf_graph):\n    #         wf_graph = self.inputs.wf_graph\n    #     else:\n    #         wf_graph = None\n    #     if isdefined(self.inputs.db):\n    #         db = self.inputs.db\n    #     else:\n    #         db = ''\n    #     # process\n    #     html_report = make_report(\n    #         pred_metrics_dict=pred_metrics_dict,\n    #         pred_census_im_dict=pred_census_im_dict,\n    #         pred_overlay_im_dict=pred_overlay_im_dict,\n    #         pred_and_acq=pred_and_acq,\n    #         brain_vol_vox=brain_vol_vox,\n    #         thr_cluster_vals=self.inputs.thr_cluster_vals,\n    #         min_seg_size=self.inputs.min_seg_size,\n    #         models_uid=models_uid,\n    #         bounding_crop=crop_brain_img,\n    #         overlayed_brainmask_1=overlayed_brainmask_1,\n    #         overlayed_brainmask_2=overlayed_brainmask_2,\n    #         isocontour_slides_FLAIR_T1=isocontour_slides_FLAIR_T1,\n    #         subject_id=subject_id,\n    #         image_size=self.inputs.image_size,\n    #         resolution=self.inputs.resolution,\n    #         percentile=self.inputs.percentile,\n    #         threshold=self.inputs.threshold,\n    #         wf_graph=wf_graph\n    #     )\n\n    #     with open('Shiva_report.html', 'w', encoding='utf-8') as fid:\n    #         fid.write(html_report)\n\n    #     # Convert the HTML file to PDF using CSS\n    #     # Creating custom CSSin addition to the main one for the pages header and the logos\n    #     postproc_dir = os.path.dirname(postproc_init)\n    #     css = CSS(os.path.join(postproc_dir, 'printed_styling.css'))\n    #     now = datetime.now(timezone.utc).strftime(\"%Y/%m/%d - %H:%M (UTC)\")\n    #     content_sub_id = f'Patient ID: {subject_id} \\A ' if subject_id else ''\n    #     header = (\n    #         '@page {'\n    #         '   @top-left {'\n    #         f'      content: \"{content_sub_id}Data-base: {db}\";'\n    #         '       font-size: 10pt;'\n    #         '       white-space: pre;'\n    #         '   }'\n    #         '   @top-center {'\n    #         f'      content: \"{now}\";'\n    #         '       font-size: 10pt;'\n    #         '   }'\n    #         '}'\n    #     )\n    #     css_header = CSS(string=header)\n    #     shiva_logo_file = os.path.join(postproc_dir, 'logo_shiva.png')\n    #     other_logos_file = os.path.join(postproc_dir, 'logos_for_shiva.png')\n    #     with open(shiva_logo_file, 'rb') as f:\n    #         image_data = f.read()\n    #         shiva_logo = base64.b64encode(image_data).decode()\n    #     with open(other_logos_file, 'rb') as f:\n    #         image_data = f.read()\n    #         other_logo = base64.b64encode(image_data).decode()\n    #     logo = (\n    #         '@page {'\n    #         '   @bottom-left {'\n    #         f'      background-image: url(data:image/png;base64,{other_logo});'\n    #         '       background-size: 552px 45px;'\n    #         '       display: inline-block;'\n    #         '       width: 560px; '\n    #         '       height: 60px;'\n    #         '       content:\"\";'\n    #         '       background-repeat: no-repeat;'\n    #         '   }'\n    #         '   @top-right-corner {'\n    #         f'      background-image: url(data:image/png;base64,{shiva_logo});'\n    #         '       background-size: 70px 70px;'\n    #         '       display: inline-block;'\n    #         '       width: 70px; '\n    #         '       height: 70px;'\n    #         '       content:\"\";'\n    #         '       background-repeat: no-repeat;'\n    #         '   }'\n    #         '}'\n    #     )\n    #     logo_css = CSS(string=logo)\n    #     HTML('Shiva_report.html').write_pdf('Shiva_report.pdf',\n    #                                         stylesheets=[css, css_header, logo_css])\n\n    #     setattr(self, 'html_report', os.path.abspath('Shiva_report.html'))\n    #     setattr(self, 'pdf_report', os.path.abspath('Shiva_report.pdf'))\n    #     return runtime\n\n    def _run_interface(self, runtime):\n        \"\"\"Skip actual report generation but create placeholder files.\"\"\"\n        print(\"SummaryReport disabled: generating empty HTML and PDF files to avoid workflow errors.\")\n\n        # Create empty HTML file\n        html_path = os.path.abspath('Shiva_report.html')\n        with open(html_path, 'w', encoding='utf-8') as f:\n            f.write('&lt;html&gt;&lt;body&gt;&lt;p&gt;Summary report generation skipped.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;')\n\n        # Create empty (but valid) PDF file header to avoid downstream rendering issues\n        pdf_path = os.path.abspath('Shiva_report.pdf')\n        with open(pdf_path, 'wb') as f:\n            f.write(b'%PDF-1.4\\n%EOF\\n')  # minimal valid PDF structure\n\n        setattr(self, 'html_report', html_path)\n        setattr(self, 'pdf_report', pdf_path)\n        return runtime\n\n\n    def _list_outputs(self):\n        \"\"\"Fill in the output structure.\"\"\"\n        outputs = self.output_spec().trait_get()\n        outputs['html_report'] = getattr(self, 'html_report')\n        outputs['pdf_report'] = getattr(self, 'pdf_report')\n\n        return outputs\n</code></pre>"},{"location":"pipelines/sMRI/wmh_quantification/","title":"WMH Quantification","text":""},{"location":"pipelines/sMRI/wmh_quantification/#cvdproc.pipelines.smri.csvd_quantification.wmh_pipeline.WMHSegmentationPipeline","title":"<code>WMHSegmentationPipeline</code>","text":"<p>WMH Segmentation and Quantification Pipeline</p>"},{"location":"pipelines/sMRI/wmh_quantification/#cvdproc.pipelines.smri.csvd_quantification.wmh_pipeline.WMHSegmentationPipeline.__init__","title":"<code>__init__</code>","text":"<p>WMH Segmentation and Quantification Pipeline</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <p>BIDSSubject object</p> required <code>session</code> <p>BIDSSession object</p> required <code>output_path</code> <p>output directory for the pipeline</p> required <code>use_which_t1w</code> <code>str</code> <p>specific string to select T1w image, e.g. 'acq-highres'. If None, T1w image is not used</p> <code>None</code> <code>use_which_flair</code> <code>str</code> <p>specific string to select FLAIR image, e.g. 'acq-highres'. If None, FLAIR image is not used</p> <code>None</code> <code>seg_method</code> <code>str</code> <p>WMH segmentation method, one of ['LST', 'LSTAI', 'WMHSynthSeg', 'truenet']</p> <code>'LST'</code> <code>seg_threshold</code> <code>float</code> <p>threshold for WMH segmentation (not used for WMHSynthSeg method)</p> <code>0.5</code> <code>location_method</code> <code>list</code> <p>list of location method, subset of ['Fazekas', 'bullseye', 'shiva', 'McDonald']</p> <code>['Fazekas']</code> <code>ventmask_method</code> <code>str</code> <p>method to get ventricle mask, one of ['SynthSeg']</p> <code>'SynthSeg'</code> <code>use_bianca_mask</code> <code>bool</code> <p>whether to use BIANCA white matter mask to constrain WMH segmentation</p> <code>False</code> <code>normalize_to_mni</code> <code>bool</code> <p>whether to normalize the WMH mask to MNI space</p> <code>False</code> <code>shape_features</code> <code>bool</code> <p>whether to calculate shape features for each WMH cluster (need normalize_to_mni=True and location_method contains 'Fazekas')</p> <code>False</code>"},{"location":"pipelines/sMRI/wmh_quantification/#cvdproc.pipelines.smri.csvd_quantification.wmh_pipeline.WMHSegmentationPipeline.check_data_requirements","title":"<code>check_data_requirements</code>","text":"<p>Check data requirements for the pipeline (At least one FLAIR image or T1w image) :return: bool</p>"},{"location":"pipelines/sMRI/wmh_quantification/#a-more-detailed-description","title":"A more detailed description:","text":""},{"location":"pipelines/sMRI/wmh_quantification/#modalities-to-use","title":"modalities to use","text":"<ul> <li>T1w</li> <li>FLAIR</li> </ul> <p>Note on T1w</p> <p>If T1w is provided, make sure it is a 3D T1w image. In the following description, we will not specify whether T1w is 2D or 3D, as we assume T1w is 3D by default.</p> <p>We handle T1w and FLAIR images using the following logic: You can provide either a T1w or a FLAIR image, or both (T1w/FLAIR/T1w+FLAIR). If T1w is provided, the segmentation will be performed on the T1w space (if FLAIR is also provided, FLAIR image will be registered to T1w space and then segmented). The concern here is that if the WMH is segmented on FLAIR image and then transformed to T1w space using a linear registration, the edges of the WMH mask may appear jagged or discontinuous.</p>"},{"location":"pipelines/sMRI/wmh_quantification/#segmentation-methods","title":"segmentation methods","text":"<p>Please refer to the table below for the available segmentation methods and their corresponding modalities and notes.</p> <p>My advice on method selection:</p> <ul> <li>The sensitivity of the methods (especially the ability to detect WMH lesions in the deep white matter). More generally, the nature of the WMH lesions in your dataset (CSVD-related WMH, MS lesions, etc.). For instance, LST-LPA and LST-AI are based on MS data.</li> <li>Whether the method will identify WMH in corpus callosum or not</li> <li>The modalities you have (T1w only, FLAIR only, or both T1w and FLAIR)</li> </ul> <p>Currently, you can only choose one method for WMH segmentation. So a possible way to choose a method is to modify the config file and run the pipeline multiple times with different methods, then compare the results.</p> method name seg_method modalities notes LST-LPA 'LST' (2D/3D) FLAIR / (2D/3D) FLAIR + T1w LST. According to my experience, this method can effectively identify PWMH lesions, but may struggle with smaller DWMH. It is a simple and convenient method for WMH segmentation and is applied in various studies. LST-AI 'LSTAI' (2D/3D) FLAIR + T1w LST-AI. Please specify 'LSTAI' rather than 'LST-AI' in the config file (to avoid extra '-', which conflicts with BIDS style). This method is more sensitive to DWMH detection, but may not identify some PWMH. Additionally, attention should be paid to the selection of thresholds, as the resulting probmap is the average of three models, and many values close to 0.33 or 0.66 may appear in the probmap. WMH-SynthSeg 'WMHSynthSeg' (2D/3D) FLAIR / T1w WMH-SynthSeg. The advantages of this method include the ability to obtain 1mm resolution results, even when the input is 2D FLAIR. However, based on my experience, the segmentation performance varies across different FLAIR sequences, and it may exaggerate WMH. FSL truenet 'truenet' 3D FLAIR / T1w / 3D FLAIR + T1w FSL truenet. The advantages of this method include the provision of multiple models, suitable for single-channel FLAIR and T1w or dual-channel FLAIR + T1w, especially FLAIR + T1w will get very good results, but the preprocessing time is relatively long (because it involves steps such as FAST segmentation). In addition, the preprocessing process seems to have some problems for the case of only FLAIR, and the results obtained without preprocessing when only FLAIR is used are consistent with the results obtained after running preprocessing."},{"location":"pipelines/sMRI/wmh_quantification/#bianca-mask","title":"bianca mask","text":"<p>If 'use_bianca_mask' is set to True, an inclusion mask is applied after the segmentation step (ref: 'The script below creates an example of inclusion mask from T1 images, which excludes cortical GM and the following structures: putamen, globus pallidus, nucleus accumbens, thalamus, brainstem, cerebellum, hippocampus, amygdala. The cortical GM is excluded from the brain mask by extracting the cortical CSF from single-subject\u2019s CSF pve map, dilating it to reach the cortical GM, and excluding these areas. The other structures are identified in MNI space, non-linearly registered to the single-subjects\u2019 images, and removed from the brain mask.' in FSL BIANCA).</p> <p>Other WMH segmentation methods not included in the pipeline:</p> <ul> <li>UBO detector</li> <li>SHiVAi</li> <li>segcsvd</li> <li>MARS-WMH</li> <li>FSL BIANCA: not included because it requires training data</li> </ul>"},{"location":"pipelines/sMRI/wmh_quantification/#lateral-ventricle-mask","title":"lateral ventricle mask","text":"<p>'ventmask_method' is used to specify the method for obtaining the lateral ventricle mask, which is required for the Fazekas location method. You can choose one of the following methods: 'SynthSeg'</p> <ul> <li>'SynthSeg': use SynthSeg</li> </ul>"},{"location":"pipelines/sMRI/wmh_quantification/#location-methods","title":"location methods","text":"<p>You can choose one or more location methods to get the location information of WMH.</p> <ul> <li>'Fazekas': classify WMH into periventricular WMH (PWMH) and deep WMH (DWMH) based on the distance to the lateral ventricles of each WMH cluster. WMH lesions totally outside the 10mm distance to the lateral ventricles are classified as DWMH. Those totally within 10mm distance or partially within 10mm distance are classified as PWMH (Theoretical should be divided into periventricular WMH and confluent WMH, but simplified to PWMH. See this Keller et al. for more information). </li> <li>'bullseye': calculate WMH volume according a bullseye parcellation scheme (see Sudre et al.). Do this classification need precomputed freesurfer recon-all results.</li> <li>'shiva': calculate WMH volume according to the SHIVA parcellation scheme (Shallow, Deep, Perivetricular, Cerebellar, and Brainstem). See shivai for more information.</li> <li>'McDonald': This utilizes the annotation of WMH clusters in LST-AI. It is more suitable for MS lesions.</li> </ul>"},{"location":"pipelines/sMRI/wmh_quantification/#normalization-to-mni-space","title":"normalization to MNI space","text":"<p>If 'normalize_to_mni' is set to True, the WMH segmentation results will be transformed to MNI space using a non-linear registration (SynthMorph).</p>"},{"location":"pipelines/sMRI/wmh_quantification/#shape-features","title":"shape features","text":"<p>If 'shape_features' is set to True, shape features of PWMH and DWMH will be calculated. We refer to the SMART-MR studies (e.g., Keller et al., Ghaznawi et al.) and Han et al.</p> <p>Methodological issues must be considered:</p> <ul> <li>The simple hypothesis is that WMH lesions will be more complex and irregular as they grow larger. However, WMH in different locations may have different growth patterns. For example, a normal aging-related PWMH lesion may reveal a cap-like shape along the lateral ventricle (Fazekas score 1, assume have 4 WMH clusters in left/right anterior/posterior horn of lateral ventricle, respectively), these WMH clusters may grow and merge to a single large PWMH lesion (Fazekas score 3). So, compare the small and large PWMH lesions directly may not be appropriate (in another word, the shape features may dramatically change when two or more WMH clusters merge).</li> <li>If you want to compare the shape features of WMH between different subjects, is it rational to simplely calculate the mean shape features of all WMH clusters in each subject? It seems OK with DWMH clusters, but not for PWMH clusters (see the above point).</li> </ul>"}]}